{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd9db79",
   "metadata": {},
   "source": [
    "# Hash Tables\n",
    "\n",
    "*Constant-time lookup with key-value mapping*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session_timer_001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# â±ï¸ OTURUM ZAMANLAYICI â€” Bu hÃ¼creyi ilk Ã§alÄ±ÅŸtÄ±rÄ±n!\n",
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "import time as _time, datetime as _dt\n",
    "from IPython.display import display, HTML as _HTML\n",
    "\n",
    "_SESSION_START = _time.time()\n",
    "_SESSION_START_STR = _dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "_HEARTBEATS = [_time.time()]\n",
    "_CELLS_RUN = [0]\n",
    "IDLE_THRESHOLD = 300\n",
    "\n",
    "def _heartbeat_hook(*args, **kwargs):\n",
    "    _HEARTBEATS.append(_time.time())\n",
    "    _CELLS_RUN[0] += 1\n",
    "\n",
    "def _calc_active_time():\n",
    "    if len(_HEARTBEATS) < 2: return 0\n",
    "    active = 0\n",
    "    for i in range(1, len(_HEARTBEATS)):\n",
    "        gap = _HEARTBEATS[i] - _HEARTBEATS[i-1]\n",
    "        active += gap if gap <= IDLE_THRESHOLD else 30\n",
    "    return int(active)\n",
    "\n",
    "try:\n",
    "    _ip = get_ipython()\n",
    "    _ip.events.register('pre_run_cell', _heartbeat_hook)\n",
    "except: pass\n",
    "\n",
    "display(_HTML(f\"\"\"<div style='background:linear-gradient(135deg,#667eea,#764ba2);padding:14px 20px;border-radius:10px;color:white;font-family:system-ui;margin:4px 0'><b>â±ï¸ Oturum BaÅŸladÄ±</b> â€” {_SESSION_START_STR}<br><span style='font-size:13px;opacity:.85'>HÃ¼cre aktiviteniz takip ediliyor. Bitince en alttaki Submit hÃ¼cresini Ã§alÄ±ÅŸtÄ±rÄ±n.</span></div>\"\"\"))\n",
    "print(f'âœ… ZamanlayÄ±cÄ± aktif. Idle eÅŸiÄŸi: {IDLE_THRESHOLD//60} dk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a437a3",
   "metadata": {},
   "source": [
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "- Understand hash functions, hash codes, and how they map keys to array indices\n",
    "- Implement collision resolution using separate chaining and open addressing (linear probing, quadratic probing, double hashing)\n",
    "- Analyze hash table performance: load factor, amortized O(1) operations, and worst-case scenarios\n",
    "- Build a hash table from scratch and understand Python's dict and set internals\n",
    "- Apply hashing patterns: frequency counting, two-sum, grouping, caching (LRU), and rolling hash for string matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee44d3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction to Hashing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a92112",
   "metadata": {},
   "source": [
    "We've seen that arrays offer O(1) access by index, but O(n) search by value. Binary search trees provide O(log n) for all operations. Can we do better? **Hash tables** achieve O(1) average-case for insert, delete, and searchâ€”the best of both worlds.\n",
    "\n",
    "> ğŸ“– **Definition:** A **hash table** (also called hash map) is a data structure that maps keys to values using a **hash function**. The hash function converts a key into an array index, enabling direct access to the stored value. When two keys map to the same index (a **collision**), special techniques resolve the conflict.\n",
    "\n",
    "> ğŸ’¡ **Hash Table Concept**\n",
    ">\n",
    "> ```\n",
    "\n",
    "Key         Hash Function    Index    Value\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"apple\"  â†’  hash(\"apple\")  â†’  2   â†’  \"red\"\n",
    "\"banana\" â†’  hash(\"banana\") â†’  5   â†’  \"yellow\"\n",
    "\"cherry\" â†’  hash(\"cherry\") â†’  2   â†’  COLLISION!\n",
    "\n",
    "Array (buckets):\n",
    "[0]  empty\n",
    "[1]  empty\n",
    "[2]  \"apple\" â†’ \"red\"  â†’  \"cherry\" â†’ \"dark red\"\n",
    "[3]  empty\n",
    "[4]  empty\n",
    "[5]  \"banana\" â†’ \"yellow\"\n",
    "[6]  empty\n",
    "                \n",
    "```\n",
    "\n",
    "### Why Hash Tables?\n",
    "\n",
    "| Operation | Array | BST | Hash Table |\n",
    "| --- | --- | --- | --- |\n",
    "| Search by key | O(n) | O(log n) | O(1)* |\n",
    "| Insert | O(1) / O(n) | O(log n) | O(1)* |\n",
    "| Delete | O(n) | O(log n) | O(1)* |\n",
    "| Ordered traversal | O(n log n) | O(n) | O(n log n) |\n",
    "\n",
    "** Average case. Worst case is O(n) with many collisions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a649a",
   "metadata": {},
   "source": [
    "**Listing 8.1 â€” Hash Table vs Other Structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Compare search performance\n",
    "n = 100000\n",
    "data = list(range(n))\n",
    "target = n - 1  # Worst case for linear search\n",
    "\n",
    "# List search - O(n)\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    _ = target in data\n",
    "list_time = time.perf_counter() - start\n",
    "\n",
    "# Set search (hash-based) - O(1)\n",
    "data_set = set(data)\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    _ = target in data_set\n",
    "set_time = time.perf_counter() - start\n",
    "\n",
    "# Dict search (hash-based) - O(1)\n",
    "data_dict = {x: x for x in data}\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    _ = target in data_dict\n",
    "dict_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"Searching for {target} in {n} elements (100 times):\")\n",
    "print(f\"  List:  {list_time*1000:.2f} ms\")\n",
    "print(f\"  Set:   {set_time*1000:.2f} ms\")\n",
    "print(f\"  Dict:  {dict_time*1000:.2f} ms\")\n",
    "speedup = list_time/set_time if set_time > 0 else float('inf')\n",
    "print(f\"\\nHash-based speedup: {speedup:.0f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d82563",
   "metadata": {},
   "source": [
    "***Figure 8.1:** Hash-based structures (set, dict) provide dramatic speedup for membership testing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586479c8",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Hash Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a66ad5",
   "metadata": {},
   "source": [
    "> ğŸ“– **Definition:** A **hash function** takes a key of arbitrary size and produces a fixed-size integer (the hash code). A good hash function is: (1) deterministicâ€”same input always gives same output, (2) uniformâ€”distributes keys evenly across buckets, (3) efficientâ€”computes quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de542f78",
   "metadata": {},
   "source": [
    "**Listing 8.2 â€” Simple Hash Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdd70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_simple(key, table_size):\n",
    "    \"\"\"Sum of ASCII values mod table_size.\"\"\"\n",
    "    return sum(ord(c) for c in str(key)) % table_size\n",
    "\n",
    "def hash_polynomial(key, table_size, base=31):\n",
    "    \"\"\"\n",
    "    Polynomial rolling hash - better distribution.\n",
    "    hash = s[0]*base^(n-1) + s[1]*base^(n-2) + ... + s[n-1]\n",
    "    \"\"\"\n",
    "    h = 0\n",
    "    for c in str(key):\n",
    "        h = (h * base + ord(c)) % table_size\n",
    "    return h\n",
    "\n",
    "def hash_djb2(key, table_size):\n",
    "    \"\"\"DJB2 hash - widely used string hash.\"\"\"\n",
    "    h = 5381\n",
    "    for c in str(key):\n",
    "        h = ((h << 5) + h) + ord(c)  # h * 33 + c\n",
    "    return h % table_size\n",
    "\n",
    "# Test hash functions\n",
    "table_size = 10\n",
    "keys = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n",
    "\n",
    "print(f\"Table size: {table_size}\\n\")\n",
    "print(f\"{'Key':<12} {'Simple':>8} {'Poly':>8} {'DJB2':>8}\")\n",
    "print(\"-\" * 40)\n",
    "for key in keys:\n",
    "    print(f\"{key:<12} {hash_simple(key, table_size):>8} \"\n",
    "          f\"{hash_polynomial(key, table_size):>8} \"\n",
    "          f\"{hash_djb2(key, table_size):>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6c7d2",
   "metadata": {},
   "source": [
    "***Figure 8.2:** Different hash functions produce different distributions. Polynomial hashes consider character position.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029b0a8",
   "metadata": {},
   "source": [
    "**Listing 8.3 â€” Python's Built-in hash()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python's hash() function\n",
    "print(\"Python hash() examples:\")\n",
    "print(f\"  hash('hello') = {hash('hello')}\")\n",
    "print(f\"  hash(42) = {hash(42)}\")\n",
    "print(f\"  hash((1, 2, 3)) = {hash((1, 2, 3))}\")\n",
    "print(f\"  hash(3.14) = {hash(3.14)}\")\n",
    "\n",
    "# Same value always gives same hash (within a session)\n",
    "print(f\"\\nConsistency: hash('test') == hash('test'): {hash('test') == hash('test')}\")\n",
    "\n",
    "# Converting hash to table index\n",
    "table_size = 16\n",
    "key = \"mykey\"\n",
    "index = hash(key) % table_size\n",
    "print(f\"\\nKey '{key}' -> hash {hash(key)} -> index {index} (table size {table_size})\")\n",
    "\n",
    "# Note: Lists are not hashable (mutable)\n",
    "try:\n",
    "    hash([1, 2, 3])\n",
    "except TypeError as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"Lists are mutable, so they can't be hashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5a390",
   "metadata": {},
   "source": [
    "***Figure 8.3:** Python's hash() works on immutable types. Use modulo to convert to table index.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bacfb5",
   "metadata": {},
   "source": [
    "**Listing 8.4 â€” Hash Distribution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fec57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_distribution(hash_func, keys, table_size):\n",
    "    \"\"\"Analyze how evenly keys are distributed.\"\"\"\n",
    "    buckets = [0] * table_size\n",
    "    for key in keys:\n",
    "        idx = hash_func(key, table_size)\n",
    "        buckets[idx] += 1\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg = len(keys) / table_size\n",
    "    variance = sum((b - avg) ** 2 for b in buckets) / table_size\n",
    "    max_bucket = max(buckets)\n",
    "    empty_buckets = buckets.count(0)\n",
    "    \n",
    "    return {\n",
    "        'variance': variance,\n",
    "        'max_bucket': max_bucket,\n",
    "        'empty': empty_buckets,\n",
    "        'distribution': buckets\n",
    "    }\n",
    "\n",
    "def hash_simple(key, size):\n",
    "    return sum(ord(c) for c in str(key)) % size\n",
    "\n",
    "def hash_polynomial(key, size):\n",
    "    h = 0\n",
    "    for c in str(key):\n",
    "        h = (h * 31 + ord(c)) % size\n",
    "    return h\n",
    "\n",
    "# Test with similar keys (worst case for simple hash)\n",
    "keys = [f\"key{i}\" for i in range(100)]\n",
    "table_size = 20\n",
    "\n",
    "print(\"Distribution analysis for 100 keys in 20 buckets:\\n\")\n",
    "\n",
    "for name, func in [(\"Simple\", hash_simple), (\"Polynomial\", hash_polynomial)]:\n",
    "    stats = analyze_distribution(func, keys, table_size)\n",
    "    print(f\"{name} hash:\")\n",
    "    print(f\"  Variance: {stats['variance']:.2f}\")\n",
    "    print(f\"  Max bucket size: {stats['max_bucket']}\")\n",
    "    print(f\"  Empty buckets: {stats['empty']}\")\n",
    "    print(f\"  Distribution: {stats['distribution'][:10]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dd8b9",
   "metadata": {},
   "source": [
    "***Figure 8.4:** Good hash functions minimize variance and empty buckets. Polynomial hash performs better on similar keys.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f3ac6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Collision Resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512ac6b",
   "metadata": {},
   "source": [
    "Since hash functions map a potentially infinite set of keys to a finite set of indices, collisions are inevitable. There are two main strategies:\n",
    "\n",
    "> ğŸ“– **Collision Resolution Strategies:** **Separate Chaining:** Each bucket stores a linked list (or other collection) of all entries that hash to that index.\n",
    "\n",
    "**Open Addressing:** When a collision occurs, probe for the next empty slot according to a probing sequence.\n",
    "\n",
    "> ğŸ’¡ **Collision Resolution Comparison**\n",
    ">\n",
    "> ```\n",
    "\n",
    "Insert keys A, B, C where hash(A) = hash(B) = hash(C) = 2\n",
    "\n",
    "Separate Chaining:            Open Addressing (Linear):\n",
    "[0] empty                     [0] empty\n",
    "[1] empty                     [1] empty\n",
    "[2] A â†’ B â†’ C                 [2] A\n",
    "[3] empty                     [3] B  (probed from 2)\n",
    "[4] empty                     [4] C  (probed from 3)\n",
    "\n",
    "Chaining: unlimited per bucket, uses extra memory\n",
    "Open addressing: all in array, better cache performance\n",
    "                \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f8a01",
   "metadata": {},
   "source": [
    "**Listing 8.5 â€” Collision Demonstration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_hash(key, size):\n",
    "    return sum(ord(c) for c in key) % size\n",
    "\n",
    "# Find keys that collide\n",
    "table_size = 10\n",
    "\n",
    "# These all have the same character sum\n",
    "colliding_keys = [\"abc\", \"bca\", \"cab\", \"acb\", \"bac\", \"cba\"]\n",
    "\n",
    "print(f\"Table size: {table_size}\")\n",
    "print(f\"\\nKeys with same character sum:\")\n",
    "for key in colliding_keys:\n",
    "    h = simple_hash(key, table_size)\n",
    "    char_sum = sum(ord(c) for c in key)\n",
    "    print(f\"  '{key}': sum={char_sum}, hash={h}\")\n",
    "\n",
    "# Also common: sequential keys\n",
    "print(f\"\\nSequential keys (common pattern):\")\n",
    "for i in range(5):\n",
    "    key = f\"user{i}\"\n",
    "    h = simple_hash(key, table_size)\n",
    "    print(f\"  '{key}': hash={h}\")\n",
    "\n",
    "print(\"\\nThis is why we need collision resolution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c826781",
   "metadata": {},
   "source": [
    "***Figure 8.5:** Collisions are commonâ€”anagrams always collide with simple sum-based hashing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40af15",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Separate Chaining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d17cab",
   "metadata": {},
   "source": [
    "**Listing 8.6 â€” Hash Table with Chaining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTableChaining:\n",
    "    \"\"\"Hash table using separate chaining.\"\"\"\n",
    "    \n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.buckets = [[] for _ in range(size)]\n",
    "        self.count = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Insert or update key-value pair.\"\"\"\n",
    "        idx = self._hash(key)\n",
    "        bucket = self.buckets[idx]\n",
    "        \n",
    "        # Check if key exists (update)\n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket[i] = (key, value)\n",
    "                return\n",
    "        \n",
    "        # Key doesn't exist (insert)\n",
    "        bucket.append((key, value))\n",
    "        self.count += 1\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Get value by key.\"\"\"\n",
    "        idx = self._hash(key)\n",
    "        for k, v in self.buckets[idx]:\n",
    "            if k == key:\n",
    "                return v\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def remove(self, key):\n",
    "        \"\"\"Remove key-value pair.\"\"\"\n",
    "        idx = self._hash(key)\n",
    "        bucket = self.buckets[idx]\n",
    "        \n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket.pop(i)\n",
    "                self.count -= 1\n",
    "                return v\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        items = []\n",
    "        for bucket in self.buckets:\n",
    "            items.extend(bucket)\n",
    "        return f\"HashTable({dict(items)})\"\n",
    "\n",
    "# Test\n",
    "ht = HashTableChaining(5)\n",
    "ht.put(\"apple\", 1)\n",
    "ht.put(\"banana\", 2)\n",
    "ht.put(\"cherry\", 3)\n",
    "ht.put(\"date\", 4)\n",
    "\n",
    "print(f\"Hash table: {ht}\")\n",
    "print(f\"get('banana'): {ht.get('banana')}\")\n",
    "\n",
    "# Show internal structure\n",
    "print(\"\\nInternal buckets:\")\n",
    "for i, bucket in enumerate(ht.buckets):\n",
    "    print(f\"  [{i}]: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b1aa8",
   "metadata": {},
   "source": [
    "***Figure 8.6:** Separate chaining stores colliding entries in a list at each bucket.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0478ce",
   "metadata": {},
   "source": [
    "**Listing 8.7 â€” Chaining with Linked List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d212be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Node for linked list in each bucket.\"\"\"\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "class HashTableLinkedChaining:\n",
    "    \"\"\"Hash table with linked list chaining.\"\"\"\n",
    "    \n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.buckets = [None] * size\n",
    "        self.count = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        idx = self._hash(key)\n",
    "        \n",
    "        # Search for existing key\n",
    "        node = self.buckets[idx]\n",
    "        while node:\n",
    "            if node.key == key:\n",
    "                node.value = value\n",
    "                return\n",
    "            node = node.next\n",
    "        \n",
    "        # Insert at head\n",
    "        new_node = Node(key, value)\n",
    "        new_node.next = self.buckets[idx]\n",
    "        self.buckets[idx] = new_node\n",
    "        self.count += 1\n",
    "    \n",
    "    def get(self, key):\n",
    "        idx = self._hash(key)\n",
    "        node = self.buckets[idx]\n",
    "        \n",
    "        while node:\n",
    "            if node.key == key:\n",
    "                return node.value\n",
    "            node = node.next\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def display_bucket(self, idx):\n",
    "        \"\"\"Show chain at bucket.\"\"\"\n",
    "        result = []\n",
    "        node = self.buckets[idx]\n",
    "        while node:\n",
    "            result.append(f\"({node.key}:{node.value})\")\n",
    "            node = node.next\n",
    "        return \" -> \".join(result) if result else \"empty\"\n",
    "\n",
    "# Test\n",
    "ht = HashTableLinkedChaining(5)\n",
    "for word in [\"cat\", \"dog\", \"rat\", \"bat\", \"ant\", \"cow\"]:\n",
    "    ht.put(word, len(word))\n",
    "\n",
    "print(\"Linked list chaining:\")\n",
    "for i in range(5):\n",
    "    print(f\"  Bucket {i}: {ht.display_bucket(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cafcf7",
   "metadata": {},
   "source": [
    "***Figure 8.7:** Linked list chaining allows O(1) insertion at head of each chain.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4ccff",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Open Addressing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896edc9c",
   "metadata": {},
   "source": [
    "Open addressing stores all entries directly in the table. When a collision occurs, we **probe** for the next empty slot.\n",
    "\n",
    "### Linear Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995539c3",
   "metadata": {},
   "source": [
    "**Listing 8.8 â€” Linear Probing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTableLinearProbing:\n",
    "    \"\"\"Hash table with linear probing.\"\"\"\n",
    "    \n",
    "    DELETED = object()  # Tombstone marker\n",
    "    \n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.keys = [None] * size\n",
    "        self.values = [None] * size\n",
    "        self.count = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        if self.count >= self.size * 0.7:  # Load factor check\n",
    "            raise Exception(\"Table is too full\")\n",
    "        \n",
    "        idx = self._hash(key)\n",
    "        \n",
    "        while self.keys[idx] is not None:\n",
    "            if self.keys[idx] == key:  # Update existing\n",
    "                self.values[idx] = value\n",
    "                return\n",
    "            if self.keys[idx] is self.DELETED:  # Reuse deleted slot\n",
    "                break\n",
    "            idx = (idx + 1) % self.size  # Linear probe\n",
    "        \n",
    "        self.keys[idx] = key\n",
    "        self.values[idx] = value\n",
    "        self.count += 1\n",
    "    \n",
    "    def get(self, key):\n",
    "        idx = self._hash(key)\n",
    "        start = idx\n",
    "        \n",
    "        while self.keys[idx] is not None:\n",
    "            if self.keys[idx] == key:\n",
    "                return self.values[idx]\n",
    "            idx = (idx + 1) % self.size\n",
    "            if idx == start:  # Full circle\n",
    "                break\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def remove(self, key):\n",
    "        idx = self._hash(key)\n",
    "        start = idx\n",
    "        \n",
    "        while self.keys[idx] is not None:\n",
    "            if self.keys[idx] == key:\n",
    "                self.keys[idx] = self.DELETED  # Tombstone\n",
    "                value = self.values[idx]\n",
    "                self.values[idx] = None\n",
    "                self.count -= 1\n",
    "                return value\n",
    "            idx = (idx + 1) % self.size\n",
    "            if idx == start:\n",
    "                break\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def display(self):\n",
    "        for i in range(self.size):\n",
    "            k = self.keys[i]\n",
    "            v = self.values[i]\n",
    "            if k is None:\n",
    "                print(f\"  [{i}]: empty\")\n",
    "            elif k is self.DELETED:\n",
    "                print(f\"  [{i}]: DELETED\")\n",
    "            else:\n",
    "                print(f\"  [{i}]: {k} = {v}\")\n",
    "\n",
    "# Test\n",
    "ht = HashTableLinearProbing(10)\n",
    "ht.put(\"apple\", 1)\n",
    "ht.put(\"banana\", 2)\n",
    "ht.put(\"cherry\", 3)\n",
    "\n",
    "print(\"After insertions:\")\n",
    "ht.display()\n",
    "\n",
    "print(f\"\\nget('banana'): {ht.get('banana')}\")\n",
    "\n",
    "ht.remove(\"banana\")\n",
    "print(\"\\nAfter removing 'banana':\")\n",
    "ht.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78f612",
   "metadata": {},
   "source": [
    "***Figure 8.8:** Linear probing checks consecutive slots. Tombstones (DELETED) preserve probe chains.*\n",
    "\n",
    "### Quadratic Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de0fb5",
   "metadata": {},
   "source": [
    "**Listing 8.9 â€” Quadratic Probing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTableQuadraticProbing:\n",
    "    \"\"\"Hash table with quadratic probing.\"\"\"\n",
    "    \n",
    "    DELETED = object()\n",
    "    \n",
    "    def __init__(self, size=11):  # Prime size recommended\n",
    "        self.size = size\n",
    "        self.keys = [None] * size\n",
    "        self.values = [None] * size\n",
    "        self.count = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def _probe(self, idx, i):\n",
    "        \"\"\"Quadratic probe: h(k) + c1*i + c2*i^2\"\"\"\n",
    "        # Using h(k) + i^2 (simpler form)\n",
    "        return (idx + i * i) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        idx = self._hash(key)\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            probe_idx = self._probe(idx, i)\n",
    "            \n",
    "            if self.keys[probe_idx] is None or self.keys[probe_idx] is self.DELETED:\n",
    "                self.keys[probe_idx] = key\n",
    "                self.values[probe_idx] = value\n",
    "                self.count += 1\n",
    "                return\n",
    "            \n",
    "            if self.keys[probe_idx] == key:\n",
    "                self.values[probe_idx] = value\n",
    "                return\n",
    "        \n",
    "        raise Exception(\"Table is full\")\n",
    "    \n",
    "    def get(self, key):\n",
    "        idx = self._hash(key)\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            probe_idx = self._probe(idx, i)\n",
    "            \n",
    "            if self.keys[probe_idx] is None:\n",
    "                break\n",
    "            if self.keys[probe_idx] == key:\n",
    "                return self.values[probe_idx]\n",
    "        \n",
    "        raise KeyError(key)\n",
    "\n",
    "# Compare linear vs quadratic probing\n",
    "print(\"Quadratic probing reduces clustering:\")\n",
    "print(\"  Linear:    0, 1, 2, 3, 4, 5, ...\")\n",
    "print(\"  Quadratic: 0, 1, 4, 9, 16, 25, ...\")\n",
    "\n",
    "ht = HashTableQuadraticProbing(11)\n",
    "for word in [\"cat\", \"act\", \"tac\"]:  # Likely collisions\n",
    "    ht.put(word, len(word))\n",
    "\n",
    "print(\"\\nTable contents:\")\n",
    "for i in range(ht.size):\n",
    "    if ht.keys[i] and ht.keys[i] is not ht.DELETED:\n",
    "        print(f\"  [{i}]: {ht.keys[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d23b62",
   "metadata": {},
   "source": [
    "***Figure 8.9:** Quadratic probing spreads entries more evenly, reducing primary clustering.*\n",
    "\n",
    "### Double Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919b36b",
   "metadata": {},
   "source": [
    "**Listing 8.10 â€” Double Hashing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTableDoubleHashing:\n",
    "    \"\"\"Hash table with double hashing.\"\"\"\n",
    "    \n",
    "    DELETED = object()\n",
    "    \n",
    "    def __init__(self, size=11):\n",
    "        self.size = size\n",
    "        self.keys = [None] * size\n",
    "        self.values = [None] * size\n",
    "        self.count = 0\n",
    "    \n",
    "    def _hash1(self, key):\n",
    "        \"\"\"Primary hash function.\"\"\"\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def _hash2(self, key):\n",
    "        \"\"\"Secondary hash function for step size.\"\"\"\n",
    "        # Must never return 0, and be coprime with size\n",
    "        return 7 - (hash(key) % 7)  # Returns 1-7\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        idx = self._hash1(key)\n",
    "        step = self._hash2(key)\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            probe_idx = (idx + i * step) % self.size\n",
    "            \n",
    "            if self.keys[probe_idx] is None or self.keys[probe_idx] is self.DELETED:\n",
    "                self.keys[probe_idx] = key\n",
    "                self.values[probe_idx] = value\n",
    "                self.count += 1\n",
    "                return\n",
    "            \n",
    "            if self.keys[probe_idx] == key:\n",
    "                self.values[probe_idx] = value\n",
    "                return\n",
    "        \n",
    "        raise Exception(\"Table is full\")\n",
    "    \n",
    "    def get(self, key):\n",
    "        idx = self._hash1(key)\n",
    "        step = self._hash2(key)\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            probe_idx = (idx + i * step) % self.size\n",
    "            \n",
    "            if self.keys[probe_idx] is None:\n",
    "                break\n",
    "            if self.keys[probe_idx] == key:\n",
    "                return self.values[probe_idx]\n",
    "        \n",
    "        raise KeyError(key)\n",
    "\n",
    "# Test\n",
    "ht = HashTableDoubleHashing(11)\n",
    "for word in [\"cat\", \"act\", \"tac\", \"dog\", \"god\"]:\n",
    "    ht.put(word, len(word))\n",
    "\n",
    "print(\"Double hashing - each key has its own probe sequence:\")\n",
    "for i in range(ht.size):\n",
    "    if ht.keys[i] and ht.keys[i] is not ht.DELETED:\n",
    "        print(f\"  [{i}]: {ht.keys[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a2ce0",
   "metadata": {},
   "source": [
    "***Figure 8.10:** Double hashing uses a second hash function to determine step size, eliminating secondary clustering.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300dde00",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Load Factor and Resizing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09df5a",
   "metadata": {},
   "source": [
    "> ğŸ“– **Definition:** The **load factor** (Î±) is the ratio of stored entries to table size: Î± = n/m. Performance degrades as Î± increases. Typically, we resize when Î± exceeds a threshold (0.7 for open addressing, 1.0 for chaining)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d701517",
   "metadata": {},
   "source": [
    "**Listing 8.11 â€” Load Factor Effects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecffa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_insert_time(table_size, num_items):\n",
    "    \"\"\"Measure time to insert items into hash table.\"\"\"\n",
    "    class SimpleHashTable:\n",
    "        def __init__(self, size):\n",
    "            self.size = size\n",
    "            self.keys = [None] * size\n",
    "            self.count = 0\n",
    "        \n",
    "        def put(self, key, value):\n",
    "            idx = hash(key) % self.size\n",
    "            probes = 0\n",
    "            while self.keys[idx] is not None:\n",
    "                if self.keys[idx] == key:\n",
    "                    return probes\n",
    "                idx = (idx + 1) % self.size\n",
    "                probes += 1\n",
    "            self.keys[idx] = key\n",
    "            self.count += 1\n",
    "            return probes\n",
    "    \n",
    "    ht = SimpleHashTable(table_size)\n",
    "    total_probes = 0\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        total_probes += ht.put(f\"key{i}\", i)\n",
    "    \n",
    "    load_factor = num_items / table_size\n",
    "    avg_probes = total_probes / num_items\n",
    "    \n",
    "    return load_factor, avg_probes\n",
    "\n",
    "# Test at different load factors\n",
    "table_size = 1000\n",
    "print(f\"Table size: {table_size}\")\n",
    "print(f\"{'Items':>8} {'Load Factor':>12} {'Avg Probes':>12}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for num_items in [100, 300, 500, 700, 900, 950]:\n",
    "    lf, ap = measure_insert_time(table_size, num_items)\n",
    "    print(f\"{num_items:>8} {lf:>12.2f} {ap:>12.2f}\")\n",
    "\n",
    "print(\"\\nNotice: probes increase dramatically above 0.7 load factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcd264",
   "metadata": {},
   "source": [
    "***Figure 8.11:** Average probes increase non-linearly with load factor. Stay below 0.7 for open addressing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538a89f",
   "metadata": {},
   "source": [
    "**Listing 8.12 â€” Dynamic Resizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicHashTable:\n",
    "    \"\"\"Hash table with automatic resizing.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_size=8):\n",
    "        self.size = initial_size\n",
    "        self.buckets = [[] for _ in range(self.size)]\n",
    "        self.count = 0\n",
    "        self.resize_threshold = 0.75\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def _resize(self, new_size):\n",
    "        \"\"\"Resize and rehash all entries.\"\"\"\n",
    "        old_buckets = self.buckets\n",
    "        self.size = new_size\n",
    "        self.buckets = [[] for _ in range(new_size)]\n",
    "        self.count = 0\n",
    "        \n",
    "        for bucket in old_buckets:\n",
    "            for key, value in bucket:\n",
    "                self.put(key, value)\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        # Check if resize needed\n",
    "        if self.count >= self.size * self.resize_threshold:\n",
    "            print(f\"  Resizing: {self.size} -> {self.size * 2}\")\n",
    "            self._resize(self.size * 2)\n",
    "        \n",
    "        idx = self._hash(key)\n",
    "        \n",
    "        # Update existing\n",
    "        for i, (k, v) in enumerate(self.buckets[idx]):\n",
    "            if k == key:\n",
    "                self.buckets[idx][i] = (key, value)\n",
    "                return\n",
    "        \n",
    "        # Insert new\n",
    "        self.buckets[idx].append((key, value))\n",
    "        self.count += 1\n",
    "    \n",
    "    def load_factor(self):\n",
    "        return self.count / self.size\n",
    "\n",
    "# Test automatic resizing\n",
    "ht = DynamicHashTable(initial_size=4)\n",
    "\n",
    "print(\"Inserting items (watching for resizes):\")\n",
    "for i in range(20):\n",
    "    ht.put(f\"key{i}\", i)\n",
    "\n",
    "print(f\"\\nFinal state:\")\n",
    "print(f\"  Items: {ht.count}\")\n",
    "print(f\"  Table size: {ht.size}\")\n",
    "print(f\"  Load factor: {ht.load_factor():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2738463",
   "metadata": {},
   "source": [
    "***Figure 8.12:** Dynamic resizing doubles table size when load factor exceeds threshold, amortizing cost over insertions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff97b4b",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Hash Table Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a34a9",
   "metadata": {},
   "source": [
    "**Listing 8.13 â€” Complete Hash Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "    \"\"\"Complete hash map with chaining and dynamic resizing.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capacity=16, load_factor=0.75):\n",
    "        self._capacity = initial_capacity\n",
    "        self._load_factor = load_factor\n",
    "        self._size = 0\n",
    "        self._buckets = [[] for _ in range(self._capacity)]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\"dict[key] = value syntax.\"\"\"\n",
    "        self._put(key, value)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"dict[key] syntax.\"\"\"\n",
    "        return self._get(key)\n",
    "    \n",
    "    def __delitem__(self, key):\n",
    "        \"\"\"del dict[key] syntax.\"\"\"\n",
    "        self._remove(key)\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        \"\"\"key in dict syntax.\"\"\"\n",
    "        try:\n",
    "            self._get(key)\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over keys.\"\"\"\n",
    "        for bucket in self._buckets:\n",
    "            for key, _ in bucket:\n",
    "                yield key\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self._capacity\n",
    "    \n",
    "    def _put(self, key, value):\n",
    "        if self._size >= self._capacity * self._load_factor:\n",
    "            self._resize()\n",
    "        \n",
    "        idx = self._hash(key)\n",
    "        bucket = self._buckets[idx]\n",
    "        \n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket[i] = (key, value)\n",
    "                return\n",
    "        \n",
    "        bucket.append((key, value))\n",
    "        self._size += 1\n",
    "    \n",
    "    def _get(self, key):\n",
    "        idx = self._hash(key)\n",
    "        for k, v in self._buckets[idx]:\n",
    "            if k == key:\n",
    "                return v\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def _remove(self, key):\n",
    "        idx = self._hash(key)\n",
    "        bucket = self._buckets[idx]\n",
    "        \n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket.pop(i)\n",
    "                self._size -= 1\n",
    "                return\n",
    "        raise KeyError(key)\n",
    "    \n",
    "    def _resize(self):\n",
    "        old_buckets = self._buckets\n",
    "        self._capacity *= 2\n",
    "        self._buckets = [[] for _ in range(self._capacity)]\n",
    "        self._size = 0\n",
    "        \n",
    "        for bucket in old_buckets:\n",
    "            for key, value in bucket:\n",
    "                self._put(key, value)\n",
    "    \n",
    "    def keys(self):\n",
    "        return list(self)\n",
    "    \n",
    "    def values(self):\n",
    "        return [self[k] for k in self]\n",
    "    \n",
    "    def items(self):\n",
    "        return [(k, self[k]) for k in self]\n",
    "\n",
    "# Test the implementation\n",
    "hm = HashMap()\n",
    "\n",
    "# Insert\n",
    "hm[\"name\"] = \"Alice\"\n",
    "hm[\"age\"] = 30\n",
    "hm[\"city\"] = \"Boston\"\n",
    "\n",
    "print(f\"HashMap contents: {dict(hm.items())}\")\n",
    "print(f\"hm['name'] = {hm['name']}\")\n",
    "print(f\"'age' in hm: {'age' in hm}\")\n",
    "print(f\"len(hm): {len(hm)}\")\n",
    "\n",
    "# Update\n",
    "hm[\"age\"] = 31\n",
    "print(f\"After update: age = {hm['age']}\")\n",
    "\n",
    "# Delete\n",
    "del hm[\"city\"]\n",
    "print(f\"After delete: {hm.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4973b3b",
   "metadata": {},
   "source": [
    "***Figure 8.13:** Complete hash map implementation with Python dict-like interface.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d16a1",
   "metadata": {},
   "source": [
    "**Listing 8.14 â€” HashSet Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashSet:\n",
    "    \"\"\"Set implementation using hash table.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capacity=16):\n",
    "        self._capacity = initial_capacity\n",
    "        self._size = 0\n",
    "        self._buckets = [[] for _ in range(self._capacity)]\n",
    "    \n",
    "    def add(self, item):\n",
    "        \"\"\"Add item to set.\"\"\"\n",
    "        if item in self:\n",
    "            return\n",
    "        \n",
    "        if self._size >= self._capacity * 0.75:\n",
    "            self._resize()\n",
    "        \n",
    "        idx = hash(item) % self._capacity\n",
    "        self._buckets[idx].append(item)\n",
    "        self._size += 1\n",
    "    \n",
    "    def remove(self, item):\n",
    "        \"\"\"Remove item from set.\"\"\"\n",
    "        idx = hash(item) % self._capacity\n",
    "        bucket = self._buckets[idx]\n",
    "        \n",
    "        for i, x in enumerate(bucket):\n",
    "            if x == item:\n",
    "                bucket.pop(i)\n",
    "                self._size -= 1\n",
    "                return\n",
    "        raise KeyError(item)\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        idx = hash(item) % self._capacity\n",
    "        return item in self._buckets[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for bucket in self._buckets:\n",
    "            for item in bucket:\n",
    "                yield item\n",
    "    \n",
    "    def _resize(self):\n",
    "        old_buckets = self._buckets\n",
    "        self._capacity *= 2\n",
    "        self._buckets = [[] for _ in range(self._capacity)]\n",
    "        self._size = 0\n",
    "        \n",
    "        for bucket in old_buckets:\n",
    "            for item in bucket:\n",
    "                self.add(item)\n",
    "    \n",
    "    def union(self, other):\n",
    "        result = HashSet()\n",
    "        for item in self:\n",
    "            result.add(item)\n",
    "        for item in other:\n",
    "            result.add(item)\n",
    "        return result\n",
    "    \n",
    "    def intersection(self, other):\n",
    "        result = HashSet()\n",
    "        for item in self:\n",
    "            if item in other:\n",
    "                result.add(item)\n",
    "        return result\n",
    "\n",
    "# Test\n",
    "s1 = HashSet()\n",
    "for x in [1, 2, 3, 4, 5]:\n",
    "    s1.add(x)\n",
    "\n",
    "s2 = HashSet()\n",
    "for x in [4, 5, 6, 7, 8]:\n",
    "    s2.add(x)\n",
    "\n",
    "print(f\"Set 1: {list(s1)}\")\n",
    "print(f\"Set 2: {list(s2)}\")\n",
    "print(f\"Union: {list(s1.union(s2))}\")\n",
    "print(f\"Intersection: {list(s1.intersection(s2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f0389",
   "metadata": {},
   "source": [
    "***Figure 8.14:** A HashSet is a hash table that only stores keys, no values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d66c6",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Python's dict and set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fede1c",
   "metadata": {},
   "source": [
    "**Listing 8.15 â€” dict Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c70563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python dict is a highly optimized hash table\n",
    "d = {}\n",
    "\n",
    "# Insert/Update - O(1)\n",
    "d[\"a\"] = 1\n",
    "d[\"b\"] = 2\n",
    "d[\"c\"] = 3\n",
    "\n",
    "# Access - O(1)\n",
    "print(f\"d['b'] = {d['b']}\")\n",
    "\n",
    "# Check existence - O(1)\n",
    "print(f\"'a' in d: {'a' in d}\")\n",
    "print(f\"'x' in d: {'x' in d}\")\n",
    "\n",
    "# Delete - O(1)\n",
    "del d[\"b\"]\n",
    "print(f\"After delete: {d}\")\n",
    "\n",
    "# Safe access with default\n",
    "print(f\"d.get('x', 'default') = {d.get('x', 'default')}\")\n",
    "\n",
    "# Iteration\n",
    "print(f\"\\nKeys: {list(d.keys())}\")\n",
    "print(f\"Values: {list(d.values())}\")\n",
    "print(f\"Items: {list(d.items())}\")\n",
    "\n",
    "# Dict comprehension\n",
    "squares = {x: x**2 for x in range(5)}\n",
    "print(f\"\\nSquares: {squares}\")\n",
    "\n",
    "# setdefault - get or set default\n",
    "counts = {}\n",
    "for char in \"hello\":\n",
    "    counts.setdefault(char, 0)\n",
    "    counts[char] += 1\n",
    "print(f\"Character counts: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4665535",
   "metadata": {},
   "source": [
    "***Figure 8.15:** Python's dict provides O(1) average-case operations with a clean interface.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb2af7",
   "metadata": {},
   "source": [
    "**Listing 8.16 â€” set Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1dd8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python set is a hash table storing only keys\n",
    "s = {1, 2, 3, 4, 5}\n",
    "\n",
    "# Add - O(1)\n",
    "s.add(6)\n",
    "print(f\"After add: {s}\")\n",
    "\n",
    "# Remove - O(1)\n",
    "s.remove(3)  # Raises KeyError if not found\n",
    "s.discard(10)  # No error if not found\n",
    "print(f\"After remove: {s}\")\n",
    "\n",
    "# Membership - O(1)\n",
    "print(f\"4 in s: {4 in s}\")\n",
    "\n",
    "# Set operations - O(len(s) + len(t))\n",
    "a = {1, 2, 3, 4}\n",
    "b = {3, 4, 5, 6}\n",
    "\n",
    "print(f\"\\na = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"Union (a | b): {a | b}\")\n",
    "print(f\"Intersection (a & b): {a & b}\")\n",
    "print(f\"Difference (a - b): {a - b}\")\n",
    "print(f\"Symmetric diff (a ^ b): {a ^ b}\")\n",
    "\n",
    "# Subset/superset\n",
    "print(f\"\\n{{1, 2}} <= a: {{1, 2}} <= a = {({1, 2} <= a)}\")\n",
    "print(f\"a >= {{1, 2}}: {a >= {1, 2}}\")\n",
    "\n",
    "# frozenset - immutable, hashable\n",
    "fs = frozenset([1, 2, 3])\n",
    "d = {fs: \"value\"}  # Can use as dict key\n",
    "print(f\"\\nfrozenset as key: {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2f7d9",
   "metadata": {},
   "source": [
    "***Figure 8.16:** Python's set provides efficient mathematical set operations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c64699",
   "metadata": {},
   "source": [
    "**Listing 8.17 â€” collections Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, OrderedDict\n",
    "\n",
    "# Counter - count occurrences\n",
    "text = \"abracadabra\"\n",
    "counts = Counter(text)\n",
    "print(f\"Counter('{text}'): {dict(counts)}\")\n",
    "print(f\"Most common 3: {counts.most_common(3)}\")\n",
    "\n",
    "# defaultdict - automatic default values\n",
    "dd = defaultdict(list)  # Default is empty list\n",
    "for word in [\"apple\", \"banana\", \"apricot\", \"blueberry\"]:\n",
    "    dd[word[0]].append(word)\n",
    "print(f\"\\ndefaultdict: {dict(dd)}\")\n",
    "\n",
    "# defaultdict with int (counts)\n",
    "word_count = defaultdict(int)\n",
    "for word in \"to be or not to be\".split():\n",
    "    word_count[word] += 1\n",
    "print(f\"Word counts: {dict(word_count)}\")\n",
    "\n",
    "# OrderedDict - remembers insertion order\n",
    "# Note: regular dict also preserves order since Python 3.7\n",
    "od = OrderedDict()\n",
    "od[\"first\"] = 1\n",
    "od[\"second\"] = 2\n",
    "od[\"third\"] = 3\n",
    "print(f\"\\nOrderedDict: {list(od.keys())}\")\n",
    "\n",
    "# Move to end\n",
    "od.move_to_end(\"first\")\n",
    "print(f\"After move_to_end: {list(od.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72fc426",
   "metadata": {},
   "source": [
    "***Figure 8.17:** The collections module provides specialized dict variants for common patterns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819cdd4",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Hash Table Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485d213",
   "metadata": {},
   "source": [
    "### Application 1: Two Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea87c5",
   "metadata": {},
   "source": [
    "**Listing 8.18 â€” Two Sum Problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sum_brute(nums, target):\n",
    "    \"\"\"O(nÂ²) - check all pairs.\"\"\"\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(i + 1, len(nums)):\n",
    "            if nums[i] + nums[j] == target:\n",
    "                return [i, j]\n",
    "    return []\n",
    "\n",
    "def two_sum_hash(nums, target):\n",
    "    \"\"\"O(n) - use hash table to find complement.\"\"\"\n",
    "    seen = {}  # value -> index\n",
    "    \n",
    "    for i, num in enumerate(nums):\n",
    "        complement = target - num\n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]\n",
    "        seen[num] = i\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Test\n",
    "nums = [2, 7, 11, 15]\n",
    "target = 9\n",
    "\n",
    "print(f\"nums = {nums}, target = {target}\")\n",
    "print(f\"Two Sum (brute): {two_sum_brute(nums, target)}\")\n",
    "print(f\"Two Sum (hash):  {two_sum_hash(nums, target)}\")\n",
    "\n",
    "# Performance comparison\n",
    "import time\n",
    "nums = list(range(10000))\n",
    "target = 19997  # Last two elements\n",
    "\n",
    "start = time.perf_counter()\n",
    "two_sum_brute(nums, target)\n",
    "brute_time = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "two_sum_hash(nums, target)\n",
    "hash_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nPerformance (10000 elements):\")\n",
    "print(f\"  Brute: {brute_time*1000:.2f} ms\")\n",
    "print(f\"  Hash:  {hash_time*1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ad8d8",
   "metadata": {},
   "source": [
    "***Figure 8.18:** Hash table reduces Two Sum from O(nÂ²) to O(n) by storing seen values.*\n",
    "\n",
    "### Application 2: Anagram Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e1a17",
   "metadata": {},
   "source": [
    "**Listing 8.19 â€” Anagram Problems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e66906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def is_anagram(s1, s2):\n",
    "    \"\"\"Check if two strings are anagrams - O(n).\"\"\"\n",
    "    return Counter(s1) == Counter(s2)\n",
    "\n",
    "def group_anagrams(words):\n",
    "    \"\"\"Group words that are anagrams of each other - O(n*k).\"\"\"\n",
    "    groups = {}\n",
    "    \n",
    "    for word in words:\n",
    "        # Sort characters as key (anagrams have same sorted form)\n",
    "        key = tuple(sorted(word))\n",
    "        if key not in groups:\n",
    "            groups[key] = []\n",
    "        groups[key].append(word)\n",
    "    \n",
    "    return list(groups.values())\n",
    "\n",
    "# Test anagram check\n",
    "print(f\"is_anagram('listen', 'silent'): {is_anagram('listen', 'silent')}\")\n",
    "print(f\"is_anagram('hello', 'world'): {is_anagram('hello', 'world')}\")\n",
    "\n",
    "# Test grouping\n",
    "words = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
    "print(f\"\\nGroup anagrams of {words}:\")\n",
    "for group in group_anagrams(words):\n",
    "    print(f\"  {group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22c634",
   "metadata": {},
   "source": [
    "***Figure 8.19:** Counter makes anagram detection trivial. Group by sorted tuple as key.*\n",
    "\n",
    "### Application 3: Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada068e8",
   "metadata": {},
   "source": [
    "**Listing 8.20 â€” Top K Frequent Elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "def top_k_frequent(nums, k):\n",
    "    \"\"\"Find k most frequent elements - O(n log k).\"\"\"\n",
    "    counts = Counter(nums)\n",
    "    return [item for item, count in counts.most_common(k)]\n",
    "\n",
    "def top_k_frequent_heap(nums, k):\n",
    "    \"\"\"Alternative using heap - O(n log k).\"\"\"\n",
    "    counts = Counter(nums)\n",
    "    # Use min-heap of size k\n",
    "    return heapq.nlargest(k, counts.keys(), key=counts.get)\n",
    "\n",
    "# Test\n",
    "nums = [1, 1, 1, 2, 2, 3, 3, 3, 3, 4]\n",
    "k = 2\n",
    "\n",
    "print(f\"nums = {nums}\")\n",
    "print(f\"Frequencies: {dict(Counter(nums))}\")\n",
    "print(f\"Top {k} frequent: {top_k_frequent(nums, k)}\")\n",
    "\n",
    "# First unique character\n",
    "def first_unique_char(s):\n",
    "    \"\"\"Find first non-repeating character - O(n).\"\"\"\n",
    "    counts = Counter(s)\n",
    "    for i, c in enumerate(s):\n",
    "        if counts[c] == 1:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "s = \"leetcode\"\n",
    "print(f\"\\nFirst unique in '{s}': index {first_unique_char(s)} ('{s[first_unique_char(s)]}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccab7ab",
   "metadata": {},
   "source": [
    "***Figure 8.20:** Counter.most_common() efficiently finds top k frequent elements.*\n",
    "\n",
    "### Application 4: LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117d5e5",
   "metadata": {},
   "source": [
    "**Listing 8.21 â€” LRU Cache Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd64ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    \"\"\"\n",
    "    Least Recently Used cache with O(1) get and put.\n",
    "    Uses OrderedDict: hash table + doubly linked list.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "    \n",
    "    def get(self, key):\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        # Move to end (most recently used)\n",
    "        self.cache.move_to_end(key)\n",
    "        return self.cache[key]\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "        self.cache[key] = value\n",
    "        \n",
    "        if len(self.cache) > self.capacity:\n",
    "            # Remove least recently used (first item)\n",
    "            self.cache.popitem(last=False)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"LRU({list(self.cache.items())})\"\n",
    "\n",
    "# Test\n",
    "cache = LRUCache(3)\n",
    "cache.put(\"a\", 1)\n",
    "cache.put(\"b\", 2)\n",
    "cache.put(\"c\", 3)\n",
    "print(f\"After adding a,b,c: {cache}\")\n",
    "\n",
    "cache.get(\"a\")  # Access 'a', moves to end\n",
    "print(f\"After accessing 'a': {cache}\")\n",
    "\n",
    "cache.put(\"d\", 4)  # Evicts 'b' (least recent)\n",
    "print(f\"After adding 'd': {cache}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c0c1a",
   "metadata": {},
   "source": [
    "***Figure 8.21:** LRU Cache uses OrderedDict for O(1) access with automatic ordering.*\n",
    "\n",
    "### Application 5: Subarray Sum Equals K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2111935",
   "metadata": {},
   "source": [
    "**Listing 8.22 â€” Subarray Sum with Hash Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subarray_sum(nums, k):\n",
    "    \"\"\"\n",
    "    Count subarrays with sum equal to k - O(n).\n",
    "    Key insight: if prefix_sum[j] - prefix_sum[i] = k,\n",
    "    then subarray [i+1, j] sums to k.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    prefix_sum = 0\n",
    "    # Map: prefix_sum -> count of occurrences\n",
    "    sum_count = {0: 1}  # Empty prefix has sum 0\n",
    "    \n",
    "    for num in nums:\n",
    "        prefix_sum += num\n",
    "        \n",
    "        # Check if (prefix_sum - k) was seen before\n",
    "        if prefix_sum - k in sum_count:\n",
    "            count += sum_count[prefix_sum - k]\n",
    "        \n",
    "        # Record current prefix sum\n",
    "        sum_count[prefix_sum] = sum_count.get(prefix_sum, 0) + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Test\n",
    "nums = [1, 1, 1]\n",
    "k = 2\n",
    "print(f\"nums = {nums}, k = {k}\")\n",
    "print(f\"Subarrays with sum {k}: {subarray_sum(nums, k)}\")\n",
    "# [1,1] at index 0-1 and [1,1] at index 1-2\n",
    "\n",
    "nums = [1, 2, 3, -2, 5]\n",
    "k = 3\n",
    "print(f\"\\nnums = {nums}, k = {k}\")\n",
    "print(f\"Subarrays with sum {k}: {subarray_sum(nums, k)}\")\n",
    "# [1,2], [3], [3,-2,5-3] - wait let's verify\n",
    "# [1,2]=3, [3]=3, [-2,5]=3 - yes, 3 subarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d949f",
   "metadata": {},
   "source": [
    "***Figure 8.22:** Prefix sum + hash map reduces subarray sum problem from O(nÂ²) to O(n).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382628f",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Common Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817af53",
   "metadata": {},
   "source": [
    "### Pattern 1: Counting and Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7752de",
   "metadata": {},
   "source": [
    "**Listing 8.23 â€” Frequency Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e499f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Pattern: Single pass counting\n",
    "def find_duplicates(nums):\n",
    "    \"\"\"Find all elements appearing more than once.\"\"\"\n",
    "    counts = Counter(nums)\n",
    "    return [num for num, count in counts.items() if count > 1]\n",
    "\n",
    "# Pattern: Check if two arrays have same frequency\n",
    "def can_construct(ransomNote, magazine):\n",
    "    \"\"\"Check if ransomNote can be made from magazine letters.\"\"\"\n",
    "    mag_count = Counter(magazine)\n",
    "    for char in ransomNote:\n",
    "        if mag_count[char] <= 0:\n",
    "            return False\n",
    "        mag_count[char] -= 1\n",
    "    return True\n",
    "\n",
    "# Pattern: Sliding window with frequency\n",
    "def longest_substring_k_distinct(s, k):\n",
    "    \"\"\"Longest substring with at most k distinct characters.\"\"\"\n",
    "    char_count = defaultdict(int)\n",
    "    left = max_len = 0\n",
    "    \n",
    "    for right, char in enumerate(s):\n",
    "        char_count[char] += 1\n",
    "        \n",
    "        while len(char_count) > k:\n",
    "            char_count[s[left]] -= 1\n",
    "            if char_count[s[left]] == 0:\n",
    "                del char_count[s[left]]\n",
    "            left += 1\n",
    "        \n",
    "        max_len = max(max_len, right - left + 1)\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "# Test\n",
    "print(f\"Duplicates in [1,2,3,1,2]: {find_duplicates([1,2,3,1,2])}\")\n",
    "print(f\"Can construct 'aa' from 'aab': {can_construct('aa', 'aab')}\")\n",
    "print(f\"Longest substring with 2 distinct in 'eceba': {longest_substring_k_distinct('eceba', 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216b009",
   "metadata": {},
   "source": [
    "***Figure 8.23:** Hash maps excel at tracking frequencies for counting and sliding window problems.*\n",
    "\n",
    "### Pattern 2: Index Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f11184",
   "metadata": {},
   "source": [
    "**Listing 8.24 â€” Index Mapping Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern: Value to index mapping\n",
    "def contains_nearby_duplicate(nums, k):\n",
    "    \"\"\"Check if duplicate exists within k distance.\"\"\"\n",
    "    last_seen = {}  # value -> last index\n",
    "    \n",
    "    for i, num in enumerate(nums):\n",
    "        if num in last_seen and i - last_seen[num] <= k:\n",
    "            return True\n",
    "        last_seen[num] = i\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Pattern: Position tracking\n",
    "def intersection(nums1, nums2):\n",
    "    \"\"\"Find intersection of two arrays.\"\"\"\n",
    "    return list(set(nums1) & set(nums2))\n",
    "\n",
    "# Pattern: Graph/relationship mapping\n",
    "def find_judges(n, trust):\n",
    "    \"\"\"\n",
    "    Find town judge: trusted by everyone, trusts nobody.\n",
    "    trust[i] = [a, b] means a trusts b.\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    \n",
    "    trust_count = {}  # person -> (trusts, trusted_by)\n",
    "    \n",
    "    for a, b in trust:\n",
    "        if a not in trust_count:\n",
    "            trust_count[a] = [0, 0]\n",
    "        if b not in trust_count:\n",
    "            trust_count[b] = [0, 0]\n",
    "        \n",
    "        trust_count[a][0] += 1  # a trusts someone\n",
    "        trust_count[b][1] += 1  # b is trusted\n",
    "    \n",
    "    for person, (trusts, trusted_by) in trust_count.items():\n",
    "        if trusts == 0 and trusted_by == n - 1:\n",
    "            return person\n",
    "    return -1\n",
    "\n",
    "print(f\"Nearby duplicate [1,2,3,1], k=3: {contains_nearby_duplicate([1,2,3,1], 3)}\")\n",
    "print(f\"Intersection [1,2,2,1] & [2,2]: {intersection([1,2,2,1], [2,2])}\")\n",
    "print(f\"Judge in n=3, trust=[[1,3],[2,3]]: {find_judges(3, [[1,3],[2,3]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd290a",
   "metadata": {},
   "source": [
    "***Figure 8.24:** Map values to indices or track relationships with hash maps.*\n",
    "\n",
    "### Pattern 3: Caching and Memoization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc7dd4",
   "metadata": {},
   "source": [
    "**Listing 8.25 â€” Memoization with Hash Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Without memoization - exponential time\n",
    "def fib_slow(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_slow(n-1) + fib_slow(n-2)\n",
    "\n",
    "# With memoization - linear time\n",
    "def fib_memo(n, cache=None):\n",
    "    if cache is None:\n",
    "        cache = {}\n",
    "    if n in cache:\n",
    "        return cache[n]\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    cache[n] = fib_memo(n-1, cache) + fib_memo(n-2, cache)\n",
    "    return cache[n]\n",
    "\n",
    "# Using functools.lru_cache\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def fib_lru(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_lru(n-1) + fib_lru(n-2)\n",
    "\n",
    "# Compare performance\n",
    "n = 30\n",
    "\n",
    "start = time.perf_counter()\n",
    "result1 = fib_slow(n)\n",
    "slow_time = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result2 = fib_memo(n)\n",
    "memo_time = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result3 = fib_lru(n)\n",
    "lru_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"fib({n}) = {result1}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  No memo:   {slow_time*1000:.2f} ms\")\n",
    "print(f\"  Manual:    {memo_time*1000:.4f} ms\")\n",
    "print(f\"  lru_cache: {lru_time*1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d961a",
   "metadata": {},
   "source": [
    "***Figure 8.25:** Memoization with hash maps transforms exponential algorithms to polynomial.*\n",
    "\n",
    "### Pattern 4: String Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a11ffe",
   "metadata": {},
   "source": [
    "**Listing 8.26 â€” Isomorphic Strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_isomorphic(s, t):\n",
    "    \"\"\"\n",
    "    Two strings are isomorphic if characters can be mapped 1-to-1.\n",
    "    'egg' -> 'add' (e->a, g->d) YES\n",
    "    'foo' -> 'bar' (f->b, o->a, o->r) NO - o maps to both a and r\n",
    "    \"\"\"\n",
    "    if len(s) != len(t):\n",
    "        return False\n",
    "    \n",
    "    s_to_t = {}  # Mapping from s chars to t chars\n",
    "    t_to_s = {}  # Mapping from t chars to s chars (for bijection)\n",
    "    \n",
    "    for c1, c2 in zip(s, t):\n",
    "        if c1 in s_to_t:\n",
    "            if s_to_t[c1] != c2:\n",
    "                return False\n",
    "        else:\n",
    "            s_to_t[c1] = c2\n",
    "        \n",
    "        if c2 in t_to_s:\n",
    "            if t_to_s[c2] != c1:\n",
    "                return False\n",
    "        else:\n",
    "            t_to_s[c2] = c1\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (\"egg\", \"add\"),   # True: e->a, g->d\n",
    "    (\"foo\", \"bar\"),   # False: o can't map to both a and r\n",
    "    (\"paper\", \"title\"),  # True: p->t, a->i, e->l, r->e\n",
    "    (\"ab\", \"aa\"),     # False: a and b both map to a\n",
    "]\n",
    "\n",
    "for s, t in test_cases:\n",
    "    print(f\"is_isomorphic('{s}', '{t}'): {is_isomorphic(s, t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b11b23",
   "metadata": {},
   "source": [
    "***Figure 8.26:** Bijective string mapping requires checking both directions.*\n",
    "\n",
    "### Pattern 5: Rolling Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de067a9",
   "metadata": {},
   "source": [
    "**Listing 8.27 â€” Rabin-Karp String Matching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rabin_karp(text, pattern):\n",
    "    \"\"\"\n",
    "    Find all occurrences of pattern in text using rolling hash.\n",
    "    Time: O(n + m) average, O(nm) worst case\n",
    "    \"\"\"\n",
    "    if not pattern or len(pattern) > len(text):\n",
    "        return []\n",
    "    \n",
    "    base = 256\n",
    "    mod = 10**9 + 7\n",
    "    n, m = len(text), len(pattern)\n",
    "    \n",
    "    # Calculate hash of pattern and first window\n",
    "    pattern_hash = 0\n",
    "    window_hash = 0\n",
    "    h = pow(base, m - 1, mod)  # base^(m-1) for rolling\n",
    "    \n",
    "    for i in range(m):\n",
    "        pattern_hash = (pattern_hash * base + ord(pattern[i])) % mod\n",
    "        window_hash = (window_hash * base + ord(text[i])) % mod\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(n - m + 1):\n",
    "        if window_hash == pattern_hash:\n",
    "            # Verify match (hash collision possible)\n",
    "            if text[i:i+m] == pattern:\n",
    "                results.append(i)\n",
    "        \n",
    "        # Roll the hash to next window\n",
    "        if i < n - m:\n",
    "            window_hash = (window_hash - ord(text[i]) * h) % mod\n",
    "            window_hash = (window_hash * base + ord(text[i + m])) % mod\n",
    "            window_hash = (window_hash + mod) % mod  # Ensure positive\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test\n",
    "text = \"AABAACAADAABAAABAA\"\n",
    "pattern = \"AABA\"\n",
    "\n",
    "positions = rabin_karp(text, pattern)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Pattern: {pattern}\")\n",
    "print(f\"Found at positions: {positions}\")\n",
    "\n",
    "# Verify\n",
    "for pos in positions:\n",
    "    print(f\"  text[{pos}:{pos+len(pattern)}] = '{text[pos:pos+len(pattern)]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaaf83f",
   "metadata": {},
   "source": [
    "***Figure 8.27:** Rolling hash enables O(1) window hash update for efficient pattern matching.*\n",
    "\n",
    "### Pattern 6: Cycle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4179a58",
   "metadata": {},
   "source": [
    "**Listing 8.28 â€” Happy Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy(n):\n",
    "    \"\"\"\n",
    "    A happy number reaches 1 when repeatedly summing squares of digits.\n",
    "    Non-happy numbers enter a cycle. Use hash set to detect cycles.\n",
    "    \"\"\"\n",
    "    def sum_of_squares(num):\n",
    "        total = 0\n",
    "        while num:\n",
    "            digit = num % 10\n",
    "            total += digit * digit\n",
    "            num //= 10\n",
    "        return total\n",
    "    \n",
    "    seen = set()\n",
    "    \n",
    "    while n != 1 and n not in seen:\n",
    "        seen.add(n)\n",
    "        n = sum_of_squares(n)\n",
    "    \n",
    "    return n == 1\n",
    "\n",
    "# Test happy numbers\n",
    "print(\"Testing numbers 1-20:\")\n",
    "happy = [n for n in range(1, 21) if is_happy(n)]\n",
    "print(f\"Happy numbers: {happy}\")\n",
    "\n",
    "# Trace one example\n",
    "n = 19\n",
    "print(f\"\\nTrace for {n}:\")\n",
    "seen = set()\n",
    "while n != 1 and n not in seen:\n",
    "    print(f\"  {n} -> \", end=\"\")\n",
    "    seen.add(n)\n",
    "    n = sum(int(d)**2 for d in str(n))\n",
    "print(f\"{n} (reached 1, happy!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ee1b8",
   "metadata": {},
   "source": [
    "***Figure 8.28:** Hash set detects cycles in sequences by tracking visited states.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c698b",
   "metadata": {},
   "source": [
    "- **Hash tables** provide O(1) average-case for insert, delete, search\n",
    "- **Hash functions** convert keys to array indices; good ones distribute uniformly\n",
    "- **Collision resolution:** chaining (lists in buckets) or open addressing (probing)\n",
    "- **Load factor** affects performance; resize when Î± exceeds threshold\n",
    "- **Python:** `dict` and `set` are highly optimized hash tables\n",
    "- **Common patterns:** counting, frequency, index mapping, caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b957e",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Common Pitfalls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65333f3",
   "metadata": {},
   "source": [
    "### Pitfall 1: Using Mutable Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c72e4b",
   "metadata": {},
   "source": [
    "**Listing 8.29 â€” Hashable Keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586513b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists are NOT hashable (mutable)\n",
    "try:\n",
    "    d = {[1, 2]: \"value\"}\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Tuples ARE hashable (immutable)\n",
    "d = {(1, 2): \"value\"}\n",
    "print(f\"Tuple key works: {d}\")\n",
    "\n",
    "# Sets are NOT hashable, but frozensets are\n",
    "try:\n",
    "    d = {{1, 2}: \"value\"}\n",
    "except TypeError as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "\n",
    "d = {frozenset([1, 2]): \"value\"}\n",
    "print(f\"Frozenset key works: {d}\")\n",
    "\n",
    "# Custom objects need __hash__ and __eq__\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.x, self.y))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.x == other.x and self.y == other.y\n",
    "\n",
    "p1, p2 = Point(1, 2), Point(1, 2)\n",
    "d = {p1: \"origin\"}\n",
    "print(f\"\\nCustom hashable object: {p1 in d, p2 in d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1e89f",
   "metadata": {},
   "source": [
    "***Figure 8.29:** Only immutable (hashable) objects can be dict keys or set members.*\n",
    "\n",
    "### Pitfall 2: Modifying Dict During Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5d8d3",
   "metadata": {},
   "source": [
    "**Listing 8.30 â€” Safe Dict Modification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRONG: Modifying dict during iteration\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "try:\n",
    "    for key in d:\n",
    "        if d[key] < 2:\n",
    "            del d[key]  # RuntimeError!\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# RIGHT: Iterate over copy of keys\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "for key in list(d.keys()):  # Create list copy\n",
    "    if d[key] < 2:\n",
    "        del d[key]\n",
    "print(f\"After safe delete: {d}\")\n",
    "\n",
    "# RIGHT: Create new dict with comprehension\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "d = {k: v for k, v in d.items() if v >= 2}\n",
    "print(f\"With comprehension: {d}\")\n",
    "\n",
    "# Same applies to sets\n",
    "s = {1, 2, 3, 4, 5}\n",
    "s = {x for x in s if x > 2}  # Safe\n",
    "print(f\"Filtered set: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622e341",
   "metadata": {},
   "source": [
    "***Figure 8.30:** Never modify a dict or set while iterating. Create a copy or use comprehension.*\n",
    "\n",
    "### Pitfall 3: Hash Collision Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047a595",
   "metadata": {},
   "source": [
    "**Listing 8.31 â€” Hash Randomization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python randomizes hash() for strings/bytes to prevent attacks\n",
    "# This means hash values differ between runs\n",
    "\n",
    "print(\"Hash values (same within this session):\")\n",
    "print(f\"  hash('hello') = {hash('hello')}\")\n",
    "print(f\"  hash('world') = {hash('world')}\")\n",
    "\n",
    "print(\"\\nNote: These values will differ in another Python session!\")\n",
    "print(\"This is a security feature (PYTHONHASHSEED).\")\n",
    "\n",
    "# Integers always hash to themselves (for small values)\n",
    "print(f\"\\nInteger hashes (predictable):\")\n",
    "for i in [0, 1, 42, -1]:\n",
    "    print(f\"  hash({i}) = {hash(i)}\")\n",
    "\n",
    "# For consistent hashing across runs, use hashlib\n",
    "import hashlib\n",
    "\n",
    "def consistent_hash(key):\n",
    "    \"\"\"Hash that's consistent across runs.\"\"\"\n",
    "    return int(hashlib.md5(str(key).encode()).hexdigest(), 16)\n",
    "\n",
    "print(f\"\\nConsistent hash('hello'): {consistent_hash('hello')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59c4fe",
   "metadata": {},
   "source": [
    "***Figure 8.31:** Python randomizes string hashes for security. Use hashlib for cross-session consistency.*\n",
    "\n",
    "### Pitfall 4: Assuming Dict Order in Old Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38cb3d",
   "metadata": {},
   "source": [
    "**Listing 8.32 â€” Dict Ordering Guarantee**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Python 3.7, dicts maintain insertion order\n",
    "d = {}\n",
    "d[\"first\"] = 1\n",
    "d[\"second\"] = 2\n",
    "d[\"third\"] = 3\n",
    "\n",
    "print(\"Dict maintains insertion order (Python 3.7+):\")\n",
    "print(f\"  Keys: {list(d.keys())}\")\n",
    "print(f\"  Values: {list(d.values())}\")\n",
    "\n",
    "# But be careful with operations that don't preserve order intent\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "d[\"a\"] = 10  # Update doesn't change order\n",
    "print(f\"\\nAfter update 'a': {list(d.keys())}\")  # Still ['a', 'b', 'c']\n",
    "\n",
    "del d[\"a\"]\n",
    "d[\"a\"] = 10  # Delete + insert moves to end\n",
    "print(f\"After delete + insert 'a': {list(d.keys())}\")  # ['b', 'c', 'a']\n",
    "\n",
    "# For explicit ordering control, use OrderedDict\n",
    "from collections import OrderedDict\n",
    "od = OrderedDict([(\"a\", 1), (\"b\", 2), (\"c\", 3)])\n",
    "od.move_to_end(\"a\")  # Explicit move\n",
    "print(f\"\\nOrderedDict after move_to_end: {list(od.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf03b6",
   "metadata": {},
   "source": [
    "***Figure 8.32:** Python 3.7+ dicts preserve insertion order. Delete+insert changes position.*\n",
    "\n",
    "### Pitfall 5: Default Dict Gotcha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61abe5",
   "metadata": {},
   "source": [
    "**Listing 8.33 â€” defaultdict Side Effects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf75466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Gotcha: Accessing missing key creates it!\n",
    "dd = defaultdict(list)\n",
    "print(f\"Before access: {dict(dd)}\")\n",
    "\n",
    "# This creates the key even though we only checked!\n",
    "if dd[\"missing\"]:\n",
    "    pass\n",
    "print(f\"After accessing 'missing': {dict(dd)}\")\n",
    "\n",
    "# Better: use 'in' to check existence\n",
    "dd2 = defaultdict(list)\n",
    "if \"missing\" in dd2:  # Doesn't create key\n",
    "    pass\n",
    "print(f\"Using 'in' check: {dict(dd2)}\")\n",
    "\n",
    "# Or use get() with default\n",
    "dd3 = defaultdict(list)\n",
    "result = dd3.get(\"missing\", [])  # Doesn't create key\n",
    "print(f\"Using get(): {dict(dd3)}\")\n",
    "\n",
    "# This matters for iteration too\n",
    "dd4 = defaultdict(int)\n",
    "dd4[\"a\"] = 1\n",
    "dd4[\"b\"] = 2\n",
    "\n",
    "# Don't do this - creates 'c'!\n",
    "for key in [\"a\", \"b\", \"c\"]:\n",
    "    print(f\"  {key}: {dd4[key]}\")\n",
    "\n",
    "print(f\"After loop: {dict(dd4)}\")  # 'c' now exists!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f432e84",
   "metadata": {},
   "source": [
    "***Figure 8.33:** Accessing a defaultdict with [] creates the key. Use 'in' or get() to check without creating.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c62e",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“ Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf9c3a",
   "metadata": {},
   "source": [
    "### Exercise 1: Valid Anagram  (â­ Easy)\n",
    "\n",
    "Given two strings s and t, return true if t is an anagram of s, and false otherwise. An anagram uses exactly the same letters the same number of times.\n",
    "\n",
    "**Expected:** (Expected: \"anagram\", \"nagaram\" â†’ True)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ Hints</summary>\n",
    "\n",
    "- **Hint 1 - Key Insight:**\n",
    "\n",
    "                        Anagrams have identical character counts. Different lengths â†’ not anagram.\n",
    "- **Hint 2 - Use Counter:**\n",
    "\n",
    "`Counter` from collections counts character frequencies automatically.\n",
    "- **Hint 3 - Compare:**\n",
    "\n",
    "                        Simply compare the two Counter objects for equality.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ [EX1]\n",
    "# Valid Anagram - Compare character frequencies\n",
    "\n",
    "def is_anagram(s, t):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation (uncomment)\n",
    "# print(is_anagram(\"anagram\", \"nagaram\"))  # True\n",
    "# print(is_anagram(\"rat\", \"car\"))  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a88e6b",
   "metadata": {},
   "source": [
    "### Exercise 2: Longest Consecutive Sequence  (â­â­ Medium)\n",
    "\n",
    "Given an unsorted array of integers, find the length of the longest consecutive elements sequence. Must run in O(n) time.\n",
    "\n",
    "**Expected:** (Expected: [100,4,200,1,3,2] â†’ 4)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ Hints</summary>\n",
    "\n",
    "- **Hint 1 - Use Set:**\n",
    "\n",
    "                        Convert to set for O(1) lookup of any number.\n",
    "- **Hint 2 - Find Sequence Starts:**\n",
    "\n",
    "                        A number starts a sequence if `(num-1)` is NOT in the set.\n",
    "- **Hint 3 - Count Forward:**\n",
    "\n",
    "                        From each start, count consecutive numbers while `(num+1)` exists.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ [EX2]\n",
    "# Longest Consecutive Sequence - O(n) time\n",
    "\n",
    "def longest_consecutive(nums):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation (uncomment)\n",
    "# print(longest_consecutive([100, 4, 200, 1, 3, 2]))  # 4 (1,2,3,4)\n",
    "# print(longest_consecutive([0, 3, 7, 2, 5, 8, 4, 6, 0, 1]))  # 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c6dd1",
   "metadata": {},
   "source": [
    "### Exercise 3: Group Anagrams  (â­â­ Medium)\n",
    "\n",
    "Given an array of strings, group anagrams together. Return the groups in any order.\n",
    "\n",
    "**Expected:** (Expected: [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"] â†’ grouped)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ Hints</summary>\n",
    "\n",
    "- **Hint 1 - Key Insight:**\n",
    "\n",
    "                        Anagrams have the same sorted characters: \"eat\" â†’ \"aet\", \"tea\" â†’ \"aet\".\n",
    "- **Hint 2 - Dict Key:**\n",
    "\n",
    "                        Use `tuple(sorted(word))` as dictionary key (lists aren't hashable).\n",
    "- **Hint 3 - defaultdict:**\n",
    "\n",
    "`defaultdict(list)` auto-creates empty lists for new keys.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ [EX3]\n",
    "# Group Anagrams - Use sorted tuple as key\n",
    "\n",
    "def group_anagrams(strs):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation (uncomment)\n",
    "# print(group_anagrams([\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]))\n",
    "# Expected: [[\"eat\",\"tea\",\"ate\"], [\"tan\",\"nat\"], [\"bat\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59411ceb",
   "metadata": {},
   "source": [
    "### Exercise 4: Word Pattern  (â­â­ Medium)\n",
    "\n",
    "Given a pattern and a string s, find if s follows the same pattern. Here \"follow\" means a full match, where each letter in pattern maps to exactly one unique word in s.\n",
    "\n",
    "**Expected:** (Expected: \"abba\", \"dog cat cat dog\" â†’ True)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ Hints</summary>\n",
    "\n",
    "- **Hint 1 - Split Words:**\n",
    "\n",
    "                        Split string s into words. Length must match pattern length.\n",
    "- **Hint 2 - Bijection:**\n",
    "\n",
    "                        Need two-way mapping: charâ†’word AND wordâ†’char must both be consistent.\n",
    "- **Hint 3 - Check Conflicts:**\n",
    "\n",
    "                        If char already maps to different word, or word maps to different char â†’ False.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ [EX4]\n",
    "# Word Pattern - Bijection mapping\n",
    "\n",
    "def word_pattern(pattern, s):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation (uncomment)\n",
    "# print(word_pattern(\"abba\", \"dog cat cat dog\"))  # True\n",
    "# print(word_pattern(\"abba\", \"dog cat cat fish\"))  # False\n",
    "# print(word_pattern(\"aaaa\", \"dog cat cat dog\"))  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44402aae",
   "metadata": {},
   "source": [
    "### Exercise 5: Implement HashMap  (â­â­â­ Hard)\n",
    "\n",
    "Design a HashMap class without using built-in dict. Support put(key, value), get(key), and remove(key).\n",
    "\n",
    "**Expected:** (Expected: Implement with array of buckets)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ Hints</summary>\n",
    "\n",
    "- **Hint 1 - Array of Buckets:**\n",
    "\n",
    "                        Use a fixed-size array (e.g., 1000). Each slot is a \"bucket\".\n",
    "- **Hint 2 - Chaining:**\n",
    "\n",
    "                        Each bucket is a list of (key, value) pairs to handle collisions.\n",
    "- **Hint 3 - Hash Function:**\n",
    "\n",
    "                        Use `key % size` to find bucket index, then linear search within bucket.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed32629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ [EX5]\n",
    "# Implement HashMap - Array of buckets with chaining\n",
    "\n",
    "class MyHashMap:\n",
    "    def __init__(self):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def get(self, key):\n",
    "        # Return value or -1 if not found\n",
    "        pass\n",
    "    \n",
    "    def remove(self, key):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "# Test your implementation (uncomment)\n",
    "# hm = MyHashMap()\n",
    "# hm.put(1, 1)\n",
    "# hm.put(2, 2)\n",
    "# print(hm.get(1))  # 1\n",
    "# print(hm.get(3))  # -1\n",
    "# hm.put(2, 1)\n",
    "# print(hm.get(2))  # 1\n",
    "# hm.remove(2)\n",
    "# print(hm.get(2))  # -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36476418",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“® Submit Your Work\n",
    "\n",
    "**When you're done with all exercises:**\n",
    "1. **Run all exercise cells** (make sure each one executed)\n",
    "2. Fill in your info in the cell below and run it\n",
    "3. Run the next cell to submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# ğŸ“® STEP 1: Fill in your info below, then run this cell\n",
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "STUDENT_ID    = \"\"     # e.g. \"2024001234\"\n",
    "STUDENT_NAME  = \"\"     # e.g. \"Ahmet YÄ±lmaz\"\n",
    "STUDENT_EMAIL = \"\"     # e.g. \"ahmet.yilmaz@istun.edu.tr\"\n",
    "CLASS_CODE    = \"\"     # code given in class\n",
    "\n",
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# Don't change anything below this line\n",
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "import re as _re\n",
    "\n",
    "_errors = []\n",
    "if not _re.match(r\"^\\d{6,12}$\", STUDENT_ID):\n",
    "    _errors.append(\"âŒ Student ID must be 6-12 digits\")\n",
    "if len(STUDENT_NAME.strip().split()) < 2:\n",
    "    _errors.append(\"âŒ Enter first and last name\")\n",
    "if not STUDENT_EMAIL.strip().lower().endswith(\"@istun.edu.tr\") or len(STUDENT_EMAIL.strip()) < 16:\n",
    "    _errors.append(\"âŒ Use your @istun.edu.tr email\")\n",
    "if len(CLASS_CODE.strip()) < 4:\n",
    "    _errors.append(\"âŒ Invalid class code\")\n",
    "\n",
    "if _errors:\n",
    "    for _e in _errors:\n",
    "        print(_e)\n",
    "    print(\"\\nâš ï¸  Fix the errors above and run this cell again.\")\n",
    "else:\n",
    "    print(f\"âœ… Info OK â€” {STUDENT_NAME} ({STUDENT_ID})\")\n",
    "    print(f\"   {STUDENT_EMAIL}\")\n",
    "    print(f\"\\nğŸ‘‰ Now run the NEXT cell to submit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# ğŸ“® STEP 2: Run this cell to submit\n",
    "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# âš ï¸  Make sure you RAN all exercise cells first!\n",
    "\n",
    "import json, re, os, urllib.request\n",
    "\nimport time as _time, datetime as _dt\n\n",
    "# â”€â”€ Calculate session duration (heartbeat-based) â”€â”€\n",
    "try:\n",
    "    _active_time = _calc_active_time()\n",
    "    _wall_time = int(_time.time() - _SESSION_START)\n",
    "    _time_on_page = _active_time\n",
    "    _a_min, _a_sec = _active_time // 60, _active_time % 60\n",
    "    _w_min, _w_sec = _wall_time // 60, _wall_time % 60\n",
    "    print(f\"â±ï¸  Active time: {_a_min}m {_a_sec}s  (wall: {_w_min}m {_w_sec}s)\")\n",
    "    print(f\"ğŸ”¢  Cells run: {_CELLS_RUN[0]}  |  Heartbeats: {len(_HEARTBEATS)}\")\n",
    "    if _active_time < 120:\n",
    "        print(\"âš ï¸  Active time < 2 min â€” Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±z hÃ¼cre sayÄ±sÄ± dÃ¼ÅŸÃ¼k olabilir.\")\n",
    "except NameError:\n",
    "    _time_on_page = 0\n",
    "    _wall_time = 0\n",
    "    print(\"âš ï¸  Timer not started â€” run the first cell next time for time tracking.\")\n\n",
    "\n",
    "WEEK = \"Week_08\"\n",
    "URL  = \"https://script.google.com/macros/s/AKfycbxepk2NvNg3Whad-WOPxdZI-mWnVJeNKCsZVspvk7Ku5YHC_oWv7376VrWLn_30nyI_vw/exec\"\n",
    "\n",
    "# â”€â”€ Check info was filled in â”€â”€\n",
    "try:\n",
    "    _sid = STUDENT_ID.strip()\n",
    "    _sname = STUDENT_NAME.strip()\n",
    "    _semail = STUDENT_EMAIL.strip().lower()\n",
    "    _scode = CLASS_CODE.strip().upper()\n",
    "except NameError:\n",
    "    raise SystemExit(\"âŒ Run the cell above first to set your info!\")\n",
    "\n",
    "if not _sid or not _sname or not _semail or not _scode:\n",
    "    raise SystemExit(\"âŒ Run the cell above first â€” some fields are empty.\")\n",
    "\n",
    "# â”€â”€ Extract exercise answers from IPython history â”€â”€\n",
    "_answers = {}\n",
    "try:\n",
    "    _ipy = get_ipython()\n",
    "    _hist = _ipy.history_manager.get_range(output=False)\n",
    "    for _sess, _line, _src in _hist:\n",
    "        _m = re.match(r\"#\\s*âœï¸\\s*\\[EX(\\w+)\\]\", _src)\n",
    "        if _m:\n",
    "            _ex_id = \"ex\" + _m.group(1)\n",
    "            _lines = _src.split(\"\\n\")\n",
    "            _clean = \"\\n\".join(_lines[1:]).strip()\n",
    "            _answers[_ex_id] = {\n",
    "                \"code\": _clean,\n",
    "                \"modified\": len(_clean) > 5\n",
    "            }\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# â”€â”€ Fallback: also check In[] from current session â”€â”€\n",
    "if not _answers:\n",
    "    try:\n",
    "        for _src in In:\n",
    "            if not _src:\n",
    "                continue\n",
    "            _m = re.match(r\"#\\s*âœï¸\\s*\\[EX(\\w+)\\]\", _src)\n",
    "            if _m:\n",
    "                _ex_id = \"ex\" + _m.group(1)\n",
    "                _lines = _src.split(\"\\n\")\n",
    "                _clean = \"\\n\".join(_lines[1:]).strip()\n",
    "                _answers[_ex_id] = {\n",
    "                    \"code\": _clean,\n",
    "                    \"modified\": len(_clean) > 5\n",
    "                }\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "# â”€â”€ Fallback: try reading notebook file (VS Code) â”€â”€\n",
    "if not _answers:\n",
    "    _nb_path = None\n",
    "    try:\n",
    "        _nb_path = __vsc_ipynb_file__\n",
    "    except NameError:\n",
    "        _candidates = [f for f in os.listdir(\".\") if f.endswith(\".ipynb\") and WEEK in f]\n",
    "        if len(_candidates) == 1:\n",
    "            _nb_path = _candidates[0]\n",
    "    if _nb_path and os.path.exists(str(_nb_path)):\n",
    "        with open(str(_nb_path), \"r\", encoding=\"utf-8\") as _f:\n",
    "            _nb = json.load(_f)\n",
    "        for _cell in _nb[\"cells\"]:\n",
    "            if _cell[\"cell_type\"] != \"code\":\n",
    "                continue\n",
    "            _src = \"\".join(_cell[\"source\"]) if isinstance(_cell[\"source\"], list) else _cell[\"source\"]\n",
    "            _m = re.match(r\"#\\s*âœï¸\\s*\\[EX(\\w+)\\]\", _src)\n",
    "            if _m:\n",
    "                _ex_id = \"ex\" + _m.group(1)\n",
    "                _lines = _src.split(\"\\n\")\n",
    "                _clean = \"\\n\".join(_lines[1:]).strip()\n",
    "                _answers[_ex_id] = {\n",
    "                    \"code\": _clean,\n",
    "                    \"modified\": len(_clean) > 5\n",
    "                }\n",
    "\n",
    "print(f\"ğŸ“ Found {len(_answers)} exercise(s): {', '.join(sorted(_answers.keys()))}\")\n",
    "\n",
    "if not _answers:\n",
    "    print(\"\\nâš ï¸  No exercise answers found!\")\n",
    "    print(\"Make sure you RAN all exercise cells before submitting.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# â”€â”€ Send â”€â”€\n",
    "_data = json.dumps({\n",
    "    \"week\": WEEK,\n",
    "    \"studentId\": _sid,\n",
    "    \"studentName\": _sname,\n",
    "    \"studentEmail\": _semail,\n",
    "    \"classCode\": _scode,\n",
    "    \"source\": \"dsa-notebook\",\n",
    "    \"sessionStart\": _SESSION_START_STR if \"_SESSION_START_STR\" in dir() else \"\",\n",
    "    \"sessionEnd\": _dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") if \"_dt\" in dir() else \"\",\n",
    "    \"wallTime\": _wall_time if \"_wall_time\" in dir() else 0,\n",
    "    \"cellsRun\": _CELLS_RUN[0] if \"_CELLS_RUN\" in dir() else 0,\n",
    "    \"timeOnPage\": _time_on_page,\n",
    "    \"answers\": _answers\n",
    "}).encode(\"utf-8\")\n",
    "\n",
    "print(\"ğŸ“¡ Submitting...\")\n",
    "\n",
    "try:\n",
    "    _req = urllib.request.Request(URL, data=_data, headers={\"Content-Type\": \"text/plain\"}, method=\"POST\")\n",
    "    _resp = urllib.request.urlopen(_req, timeout=30)\n",
    "    _result = json.loads(_resp.read().decode())\n",
    "    if _result.get(\"success\"):\n",
    "        print(f\"\\nâœ… {_result['message']}\")\n",
    "        print(\"ğŸ“§ Check your email for confirmation.\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ {_result.get('message', 'Submission failed')}\")\n",
    "except Exception as _e:\n",
    "    try:\n",
    "        _req = urllib.request.Request(URL, data=_data, headers={\"Content-Type\": \"text/plain\"}, method=\"POST\")\n",
    "        urllib.request.urlopen(_req, timeout=10)\n",
    "    except:\n",
    "        pass\n",
    "    print(f\"\\nâš ï¸  Request sent â€” check your email for confirmation.\")\n",
    "    print(f\"(If no email arrives, try again or contact your instructor)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}